{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list= [\n",
    "    '我喜欢吃苹果和桃子尤其是桃子',\n",
    "    '小甲喜欢吃苹果', \n",
    "    '小乙喜爱吃西瓜', \n",
    "    '小丁喜欢吃苹果西瓜'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/fuwen/anaconda3/envs/bj1/lib/python3.7/site-packages/jieba/__init__.py\", line 154, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmp9g8n85fv' -> '/tmp/jieba.cache'\n",
      "Loading model cost 0.923 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['我', '喜欢', '吃', '苹果', '和', '桃子', '尤其', '是', '桃子'], ['小甲', '喜欢', '吃', '苹果'], ['小乙', '喜爱', '吃', '西瓜'], ['小丁', '喜欢', '吃', '苹果', '西瓜']]\n",
      "['我 喜欢 吃 苹果 和 桃子 尤其 是 桃子', '小甲 喜欢 吃 苹果', '小乙 喜爱 吃 西瓜', '小丁 喜欢 吃 苹果 西瓜']\n"
     ]
    }
   ],
   "source": [
    "# sklearn会对语料自动进行分词，默认以空格拆分，并且默认过滤掉长度为1的token和标点符号；而gensim需要先对语料分词后才能处理\n",
    "import jieba\n",
    "ws = [jieba.lcut(s) for s in text_list]  # gensim的输入\n",
    "ws_sk = [' '.join(s) for s in ws]  # sklearn的输入\n",
    "print(ws)\n",
    "print(ws_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吃', '和', '喜欢', '喜爱', '小丁', '小乙', '小甲', '尤其', '我', '是', '桃子', '苹果', '西瓜']\n",
      "{'我': 8, '喜欢': 2, '吃': 0, '苹果': 11, '和': 1, '桃子': 10, '尤其': 7, '是': 9, '小甲': 6, '小乙': 5, '喜爱': 3, '西瓜': 12, '小丁': 4}\n",
      "[[1 1 1 0 0 0 0 1 1 1 2 1 0]\n",
      " [1 0 1 0 0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      " [1 0 1 0 1 0 0 0 0 0 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17311114, 0.33173127, 0.21173977, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33173127, 0.33173127, 0.33173127,\n",
       "        0.66346254, 0.21173977, 0.        ],\n",
       "       [0.3612126 , 0.        , 0.44181486, 0.        , 0.        ,\n",
       "        0.        , 0.69218835, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44181486, 0.        ],\n",
       "       [0.30675807, 0.        , 0.        , 0.58783765, 0.        ,\n",
       "        0.58783765, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.46345796],\n",
       "       [0.31707032, 0.        , 0.38782252, 0.        , 0.60759891,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38782252, 0.47903796]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "# token_pattern为分词方式，默认过滤掉长度为1的token和标点符号，即`r\"(?u)\\b\\w\\w+\\b\"`，\n",
    "#为了保证分词结果和我们使用jieba的分词结果一致，这里对分词方式做修改\n",
    "# \\w 匹配字母或数字或下划线或汉字 等价于 '[^A-Za-z0-9_]'\n",
    "# [\\w]+和\\w+没有区别，都是匹配数字和字母下划线的多个字符\n",
    "#\\b单词的开头或结尾\n",
    "# 将re.U提前在正则表达式中加入r\"(?u)\n",
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "count = vectorizer.fit_transform(ws_sk)#我 喜欢 吃 苹果 和 桃子 尤其 是 桃子\n",
    "# print(count)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(vectorizer.vocabulary_)\n",
    "print(count.toarray())\n",
    "\n",
    "# get_feature_names()可看到所有文本的关键字\n",
    "# vocabulary_可看到所有文本的关键字和其位置\n",
    "# toarray()可看到词频矩阵的结果\n",
    "\n",
    "#TfidfTransformer是统计CountVectorizer中每个词语的tf-idf权值\n",
    "transformer = TfidfTransformer()\n",
    "tfidf_matrix = transformer.fit_transform(count)\n",
    "tfidf_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17311114, 0.33173127, 0.21173977, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33173127, 0.33173127, 0.33173127,\n",
       "        0.66346254, 0.21173977, 0.        ],\n",
       "       [0.3612126 , 0.        , 0.44181486, 0.        , 0.        ,\n",
       "        0.        , 0.69218835, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44181486, 0.        ],\n",
       "       [0.30675807, 0.        , 0.        , 0.58783765, 0.        ,\n",
       "        0.58783765, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.46345796],\n",
       "       [0.31707032, 0.        , 0.38782252, 0.        , 0.60759891,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38782252, 0.47903796]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#skl方法二\n",
    "tfidf_vec = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "tfidf_matrix = tfidf_vec.fit_transform(ws_sk)\n",
    "\n",
    "# tfidf_vec.get_feature_names()\n",
    "\n",
    "# tfidf_vec.vocabulary_\n",
    "tfidf_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'吃': 0, '和': 1, '喜欢': 2, '尤其': 3, '我': 4, '是': 5, '桃子': 6, '苹果': 7, '小甲': 8, '喜爱': 9, '小乙': 10, '西瓜': 11, '小丁': 12}\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1)], [(0, 1), (2, 1), (7, 1), (8, 1)], [(0, 1), (9, 1), (10, 1), (11, 1)], [(0, 1), (2, 1), (7, 1), (11, 1), (12, 1)]]\n",
      "[(1, 0.35166544195065214), (2, 0.07297717280499404), (3, 0.35166544195065214), (4, 0.35166544195065214), (5, 0.35166544195065214), (6, 0.7033308839013043), (7, 0.07297717280499404)]\n",
      "['小明', '喜欢', '吃', '苹果']\n",
      "[(0, 1), (2, 1), (7, 1)]\n",
      "[0.1032053  0.28159946 0.         0.2538916 ]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "dictionary = corpora.Dictionary(ws)  # 建立词典\n",
    "\n",
    "print(dictionary.token2id)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in ws]\n",
    "\n",
    "print(corpus)\n",
    "\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "tfidf_matrix_gensim = tfidf_model[corpus]  # 得到语料的tfidf值\n",
    "print(tfidf_matrix_gensim[0])\n",
    "\n",
    "\n",
    "\n",
    "text_new = '小明喜欢吃苹果'  # 一条新数据\n",
    "ws_new = jieba.lcut(text_new)\n",
    "print(ws_new)\n",
    "\n",
    "vec_new = dictionary.doc2bow(ws_new)\n",
    "print(vec_new)\n",
    "\n",
    "# 计算与新数据的相似度\n",
    "index = similarities.SparseMatrixSimilarity(tfidf_model [corpus], num_features=len(dictionary.keys()))\n",
    "# print(index)\n",
    "print(index[tfidf_model[vec_new]])# 与第二条相似度最高，最后一条次高，结果还是比较合理的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'我': 8,\n",
       " '喜欢': 2,\n",
       " '吃': 0,\n",
       " '苹果': 11,\n",
       " '和': 1,\n",
       " '桃子': 10,\n",
       " '尤其': 7,\n",
       " '是': 9,\n",
       " '小甲': 6,\n",
       " '小乙': 5,\n",
       " '喜爱': 3,\n",
       " '西瓜': 12,\n",
       " '小丁': 4}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'吃': 0,\n",
       " '和': 1,\n",
       " '喜欢': 2,\n",
       " '尤其': 3,\n",
       " '我': 4,\n",
       " '是': 5,\n",
       " '桃子': 6,\n",
       " '苹果': 7,\n",
       " '小甲': 8,\n",
       " '喜爱': 9,\n",
       " '小乙': 10,\n",
       " '西瓜': 11,\n",
       " '小丁': 12}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1731111372459707, 0.3317312678886485, 0.21173977118307816, 0.0, 0.0, 0.0, 0.0, 0.3317312678886485, 0.3317312678886485, 0.3317312678886485, 0.663462535777297, 0.21173977118307816, 0.0]\n",
      "[(1, 0.35166544195065214), (2, 0.07297717280499404), (3, 0.35166544195065214), (4, 0.35166544195065214), (5, 0.35166544195065214), (6, 0.7033308839013043), (7, 0.07297717280499404)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf_matrix.toarray()[0]))\n",
    "print(tfidf_matrix_gensim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36121259819515966, 0.0, 0.4418148601358603, 0.0, 0.0, 0.0, 0.6921883541575676, 0.0, 0.0, 0.0, 0.0, 0.4418148601358603, 0.0]\n",
      "[(2, 0.19912088989639576), (7, 0.19912088989639576), (8, 0.9595320434533362)]\n"
     ]
    }
   ],
   "source": [
    "print(list(tfidf_matrix.toarray()[1]))\n",
    "print(tfidf_matrix_gensim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bj1",
   "language": "python",
   "name": "bj1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
